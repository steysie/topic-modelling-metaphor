{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import fbeta_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts for classification and scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally, we tried 11 different classifiers, but eventually decided to report scores only for the top 3: Logistic Regression, Linear SVM and Neural Network. Uncomment lines with classifiers and their names if you wou want to try more than three classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Logistic Regression\", \n",
    "         #\"Logisitic Regression SGD\", \n",
    "         \"Linear SVM\", \n",
    "         #\"RBF SVM\", \n",
    "         #\"Naive Bayes\", \n",
    "         #\"Gaussian Process\", \n",
    "         #\"Decision Tree\", \n",
    "         #\"Random Forest\", \n",
    "         \"Neural Net\", \n",
    "         #\"AdaBoost\", \n",
    "         #\"Nearest Heighbors\"\n",
    "         ]\n",
    "\n",
    "classifiers = [LogisticRegression(class_weight='balanced', solver='liblinear', fit_intercept=True, max_iter=10000),\n",
    "               #linear_model.SGDClassifier(max_iter=50000, tol=1e-3, loss='log', class_weight='balanced'),\n",
    "               SVC(kernel=\"linear\", C=0.025, max_iter=10000),\n",
    "               #SVC(gamma=2), \n",
    "               #GaussianNB(),\n",
    "               #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "               #DecisionTreeClassifier(max_depth=10),\n",
    "               #RandomForestClassifier(max_depth=10, n_estimators=10),\n",
    "               MLPClassifier(alpha=0.1, max_iter=5000, learning_rate='adaptive'),\n",
    "               #AdaBoostClassifier(),\n",
    "               #KNeighborsClassifier(n_neighbors=2)\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, k_fold=5):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    train_results = {}    # {'clf': {'accuracy':[], 'precision':[], 'recall':[], 'f1':[])}\n",
    "\n",
    "    #kf = KFold(k_fold, shuffle=True, random_state=42)\n",
    "    kf = StratifiedKFold(k_fold, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_num = 1\n",
    "\n",
    "    for train_ind, val_ind in kf.split(X, y):\n",
    "        # Assign CV IDX\n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind]\n",
    "        \n",
    "        # Scale Data\n",
    "        # scaler = StandardScaler()\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scale = scaler.fit_transform(X_train)\n",
    "        X_val_scale = scaler.transform(X_val)\n",
    "        \n",
    "        # print(\"Fold num: \", fold_num)\n",
    "\n",
    "        for name, clf in zip(names, classifiers):\n",
    "\n",
    "            if name not in train_results:\n",
    "                train_results[name] = {'accuracy':[], 'precision':[], 'recall':[], 'f1':[]} # 'train_time':[]}\n",
    "\n",
    "            # print(\"Training: \", name)\n",
    "            #start_time = time.time()\n",
    "\n",
    "            model = clf.fit(X_train_scale, y_train)\n",
    "            y_pred = model.predict(X_val_scale)\n",
    "\n",
    "            train_results[name]['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "            train_results[name]['precision'].append(precision_score(y_val, y_pred))\n",
    "            train_results[name]['recall'].append(recall_score(y_val, y_pred))\n",
    "            train_results[name]['f1'].append(f1_score(y_val, y_pred))\n",
    "            #train_results[name]['train_time'].append(time.time() - start_time)\n",
    "\n",
    "            #print(\"Run Time: \", time.time() - start_time)\n",
    "        \n",
    "        fold_num += 1\n",
    "        # print()\n",
    "    return train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    " def scores(results, mode='print'):   \n",
    "    '''Print or return metric report for all tested classifiers\n",
    "    '''\n",
    "    if mode == 'return':\n",
    "        result = \"\"\n",
    "        for clf, scores in results.items():\n",
    "            result += \"Scores for {}\\n\".format(clf)\n",
    "            result += f\"\\t Train accuracy: {np.mean(scores['accuracy']):.3f} +- {np.std(scores['accuracy']):.3f}\\n\"\n",
    "            result += f\"\\t Train precision: {np.mean(scores['precision']):.3f} +- {np.std(scores['precision']):.3f}\\n\"\n",
    "            result += f\"\\t Train recall: {np.mean(scores['recall']):.3f} +- {np.std(scores['recall']):.3f}\\n\"\n",
    "            result += f\"\\t Train f1-score: {np.mean(scores['f1']):.3f} +- {np.std(scores['f1']):.3f}\\n\"\n",
    "        return result\n",
    "        \n",
    "    elif mode == 'print':\n",
    "        for clf, scores in results.items():\n",
    "\n",
    "            print(\"Scores for \", clf)\n",
    "            print(f\"\\t Train accuracy: {np.mean(scores['accuracy']):.3f} +- {np.std(scores['accuracy']):.3f}\")\n",
    "            print(f\"\\t Train precision: {np.mean(scores['precision']):.3f} +- {np.std(scores['precision']):.3f}\")\n",
    "            print(f\"\\t Train recall: {np.mean(scores['recall']):.3f} +- {np.std(scores['recall']):.3f}\")\n",
    "            print(f\"\\t Train f1-score: {np.mean(scores['f1']):.3f} +- {np.std(scores['f1']):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log(model_name, results):\n",
    "    # Print metric report for all tested classifiers\n",
    "    with open(model_name+\"train.txt\", \"w\") as f:\n",
    "        print(model_name, file=f)\n",
    "        for clf, scores in results.items():\n",
    "            print(\"Scores for \", clf, file=f)\n",
    "            print(f\"\\t Train accuracy: {np.mean(scores['accuracy']):.3f} +- {np.std(scores['accuracy']):.3f}\", file=f)\n",
    "            print(f\"\\t Train precision: {np.mean(scores['precision']):.3f} +- {np.std(scores['precision']):.3f}\", file=f)\n",
    "            print(f\"\\t Train recall: {np.mean(scores['recall']):.3f} +- {np.std(scores['recall']):.3f}\", file=f)\n",
    "            print(f\"\\t Train f1-score: {np.mean(scores['f1']):.3f} +- {np.std(scores['f1']):.3f}\", file=f)\n",
    "            #print(f\"\\t Train time: {np.sum(scores['train_time']):.3f}\", file=f)\n",
    "#save_log(model_name, train_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset with Topic Features from ARTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sents</th>\n",
       "      <th>targets</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_70</th>\n",
       "      <th>topic_71</th>\n",
       "      <th>topic_72</th>\n",
       "      <th>topic_73</th>\n",
       "      <th>topic_74</th>\n",
       "      <th>topic_75</th>\n",
       "      <th>topic_76</th>\n",
       "      <th>topic_77</th>\n",
       "      <th>topic_78</th>\n",
       "      <th>topic_79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>нужно_PRED весь_ADJF время_NOUN бомбардировать...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.012471</td>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.025298</td>\n",
       "      <td>0.011624</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.011436</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011415</td>\n",
       "      <td>0.012276</td>\n",
       "      <td>0.011373</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.011616</td>\n",
       "      <td>0.012746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>добрынин_NOUN говорить_VERB шевченко_NOUN цент...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010570</td>\n",
       "      <td>0.010208</td>\n",
       "      <td>0.010947</td>\n",
       "      <td>0.010107</td>\n",
       "      <td>0.014802</td>\n",
       "      <td>0.011982</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>0.013713</td>\n",
       "      <td>0.010230</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.010489</td>\n",
       "      <td>0.009813</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>0.014215</td>\n",
       "      <td>0.010244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>принять_INFN внимание_NOUN настойчиво_ADVB гру...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009617</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>0.007861</td>\n",
       "      <td>0.007788</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>0.008243</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>0.007644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              sents  targets  \\\n",
       "0           0  нужно_PRED весь_ADJF время_NOUN бомбардировать...        1   \n",
       "1           1  добрынин_NOUN говорить_VERB шевченко_NOUN цент...        1   \n",
       "2           2  принять_INFN внимание_NOUN настойчиво_ADVB гру...        1   \n",
       "\n",
       "    topic_0   topic_1   topic_2   topic_3   topic_4   topic_5   topic_6  ...  \\\n",
       "0  0.011593  0.011700  0.012471  0.011675  0.025298  0.011624  0.011400  ...   \n",
       "1  0.010570  0.010208  0.010947  0.010107  0.014802  0.011982  0.010549  ...   \n",
       "2  0.009617  0.008274  0.007861  0.007788  0.018796  0.010173  0.008079  ...   \n",
       "\n",
       "   topic_70  topic_71  topic_72  topic_73  topic_74  topic_75  topic_76  \\\n",
       "0  0.017775  0.011436  0.011364  0.011415  0.012276  0.011373  0.011364   \n",
       "1  0.010908  0.009851  0.013713  0.010230  0.012501  0.010489  0.009813   \n",
       "2  0.008647  0.007684  0.007576  0.009606  0.009331  0.008243  0.008101   \n",
       "\n",
       "   topic_77  topic_78  topic_79  \n",
       "0  0.011990  0.011616  0.012746  \n",
       "1  0.010720  0.014215  0.010244  \n",
       "2  0.007904  0.008173  0.007644  \n",
       "\n",
       "[3 rows x 83 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./artm/thetas/metcorp_tm_dense_280.csv', index_col=None)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7077, 7077)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 3:53].values.tolist()\n",
    "y = df['targets']\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for  Logistic Regression\n",
      "\t Train accuracy: 0.699 +- 0.008\n",
      "\t Train precision: 0.691 +- 0.008\n",
      "\t Train recall: 0.721 +- 0.018\n",
      "\t Train f1-score: 0.705 +- 0.010\n",
      "Scores for  Linear SVM\n",
      "\t Train accuracy: 0.670 +- 0.006\n",
      "\t Train precision: 0.631 +- 0.004\n",
      "\t Train recall: 0.819 +- 0.015\n",
      "\t Train f1-score: 0.713 +- 0.007\n",
      "Scores for  Neural Net\n",
      "\t Train accuracy: 0.698 +- 0.008\n",
      "\t Train precision: 0.691 +- 0.009\n",
      "\t Train recall: 0.715 +- 0.015\n",
      "\t Train f1-score: 0.703 +- 0.009\n"
     ]
    }
   ],
   "source": [
    "train_results = train(X, y)\n",
    "scores(train_results)\n",
    "save_log(model_name=\"Metcorp_clf_sklearn\", results=train_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk train on multiple ARTM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_stdin():\n",
    "    if hasattr(tqdm, '_instances'):\n",
    "        for instance in list(tqdm._instances):\n",
    "            tqdm._decr_instances(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_train(theta_table_names, theta_dir='', save_log_name='bulk_train_output.txt'):\n",
    "    '''\n",
    "    Train and evaluate classifiers on different feature tables.\n",
    "    \n",
    "    Args:\n",
    "        theta_table_names:      list of all theta dataframe names, where features are in [3:52] columns,\n",
    "                                column 1 - sentences, column 2 - labels.\n",
    "        theta_dir:              set root dir for theta tables, if they are not in the same dir \n",
    "                                as the notebook. Otherwise, leave as is.\n",
    "        save_log_name:          filename to save the logs. You can mention the relative/absolute path as well,\n",
    "                                but make sure the directory exists on disk or elsewise an error might pop up\n",
    "    '''\n",
    "    clear_stdin()\n",
    "    bulk_results = []\n",
    "    \n",
    "    for theta in tqdm(theta_table_names):\n",
    "        features = pd.read_csv(theta_dir+theta, index_col=None)\n",
    "        \n",
    "        X = features.iloc[:, 3:53].values.tolist()\n",
    "        y = features['targets']\n",
    "        # X = df.values.tolist()    # if it is only theta table\n",
    "        \n",
    "        train_results = train(X, y)\n",
    "        model_results = scores(train_results, mode='return')\n",
    "        bulk_results.append(f'{theta}\\n{model_results}')\n",
    "        \n",
    "    \n",
    "    with open(save_log_name, 'wt', encoding='utf-8') as f:\n",
    "        for i in bulk_results:\n",
    "            print(i, file=f)\n",
    "            print('='*30, file=f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_nums=[40,50,60,70,80,90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:08<00:00, 11.46s/it]\n"
     ]
    }
   ],
   "source": [
    "bulk_train(theta_table_names=['metcorp_tm_sparse{}.csv'.format(i) for i in topic_nums], theta_dir='./artm/thetas/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milti-feature Classifier\n",
    "### TM + lex / morph / concr-absrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import ast, csv\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from metcorp_utils import compute_statistics, assign_scores, freq_table   # custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes that were eliminated from metaphor corpus\n",
    "emptied_indexes = [325, 379, 417, 909, 914, 1067, 1146, 1193, 1214, 1301, 1325, 1393, 1398, 1412, 1826,\n",
    "                   1830, 1864, 1891, 2015, 2016, 2017, 2051, 2078, 2080, 2081, 2086, 2138, 2154, 2178, \n",
    "                   2229, 2296, 2425, 2945, 3116, 3128, 3437, 3685, 4036, 4182, 4183, 4770, 4809, 4928, \n",
    "                   4984, 5039, 5134, 5136, 5228, 5248, 5322, 5493, 5543, 6059, 6067, 6093, 6109, 6218, \n",
    "                   6232, 6288, 6301, 6461, 6663, 6769, 6924, 7136]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7077\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "      <th>sentid</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>бомбардировать#1</td>\n",
       "      <td>['время', 'ребенок', 'музыка']</td>\n",
       "      <td>['ADV', 'PART', ',', 'SPRO', 'PART', 'ADV', 'A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>бомбардировать#2</td>\n",
       "      <td>['добрынин', 'говорить', 'шевченко', 'центр', ...</td>\n",
       "      <td>['S anim nom', 'ADV', 'V ipf praet indic', 'S ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>бомбардировать#3</td>\n",
       "      <td>['принять', 'внимание', 'настойчиво', 'группа'...</td>\n",
       "      <td>['CONJ', 'V pf - inf', 'ВО', 'S inan acc', ','...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  class            sentid  \\\n",
       "0      0      1  бомбардировать#1   \n",
       "1      1      1  бомбардировать#2   \n",
       "2      2      1  бомбардировать#3   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0                     ['время', 'ребенок', 'музыка']   \n",
       "1  ['добрынин', 'говорить', 'шевченко', 'центр', ...   \n",
       "2  ['принять', 'внимание', 'настойчиво', 'группа'...   \n",
       "\n",
       "                                                 pos  \n",
       "0  ['ADV', 'PART', ',', 'SPRO', 'PART', 'ADV', 'A...  \n",
       "1  ['S anim nom', 'ADV', 'V ipf praet indic', 'S ...  \n",
       "2  ['CONJ', 'V pf - inf', 'ВО', 'S inan acc', ','...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and Delete rows that were eliminated when retrieving features for the metcorp (1-2 word ones).\n",
    "infile = r'lex_pos140420.csv'\n",
    "df = pd.read_csv(infile, sep = '\\t', index_col = 0)\n",
    "df = df.drop([df.index[i] for i in emptied_indexes]).reset_index()\n",
    "print(len(df))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Concreteness / Abstractness features in Metaphor corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "concr = pd.read_csv('concretness5.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>words_perf_verbs</th>\n",
       "      <th>words_imperf_verbs</th>\n",
       "      <th>things_concr_k10</th>\n",
       "      <th>abstr_concr_k10</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>гребенка_NOUN</td>\n",
       "      <td>гребенка_NOUN</td>\n",
       "      <td>0.300831</td>\n",
       "      <td>0.186778</td>\n",
       "      <td>0.243805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>бюджет_NOUN</td>\n",
       "      <td>бюджет_NOUN</td>\n",
       "      <td>0.170042</td>\n",
       "      <td>0.259276</td>\n",
       "      <td>0.214659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>письмо_NOUN</td>\n",
       "      <td>письмо_NOUN</td>\n",
       "      <td>0.260119</td>\n",
       "      <td>0.216631</td>\n",
       "      <td>0.238375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>правительство_NOUN</td>\n",
       "      <td>правительство_NOUN</td>\n",
       "      <td>0.142006</td>\n",
       "      <td>0.263686</td>\n",
       "      <td>0.202846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>зарплата_NOUN</td>\n",
       "      <td>зарплата_NOUN</td>\n",
       "      <td>0.166051</td>\n",
       "      <td>0.247007</td>\n",
       "      <td>0.206529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    words_perf_verbs  words_imperf_verbs  things_concr_k10  \\\n",
       "0           0       гребенка_NOUN       гребенка_NOUN          0.300831   \n",
       "1           1         бюджет_NOUN         бюджет_NOUN          0.170042   \n",
       "2           2         письмо_NOUN         письмо_NOUN          0.260119   \n",
       "3           3  правительство_NOUN  правительство_NOUN          0.142006   \n",
       "4           4       зарплата_NOUN       зарплата_NOUN          0.166051   \n",
       "\n",
       "   abstr_concr_k10      mean  \n",
       "0         0.186778  0.243805  \n",
       "1         0.259276  0.214659  \n",
       "2         0.216631  0.238375  \n",
       "3         0.263686  0.202846  \n",
       "4         0.247007  0.206529  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'письмо_NOUN' in concr['words_perf_verbs'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lemma = pd.read_csv('metcorp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_tags(text):\n",
    "    text = re.sub('_[A-Z]+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sents</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>нужно весь время бомбардировать ребёнок музыка</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>добрынин говорить шевченко центр бомбардироват...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>принять внимание настойчиво группа особый инте...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>кроме покупка рука сохранять природный ресурс ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>сигнал настойчиво бомбардировать день придать ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sents  targets\n",
       "0     нужно весь время бомбардировать ребёнок музыка        1\n",
       "1  добрынин говорить шевченко центр бомбардироват...        1\n",
       "2  принять внимание настойчиво группа особый инте...        1\n",
       "3  кроме покупка рука сохранять природный ресурс ...        1\n",
       "4  сигнал настойчиво бомбардировать день придать ...        1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_lemma['sents'] = [remove_tags(i) for i in pos_lemma['sents']]\n",
    "pos_lemma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lemma.to_csv('lemma_targ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "concr['words_perf_verbs'] = [remove_tags(i) for i in concr['words_perf_verbs']]\n",
    "concr['words_imperf_verbs'] = [remove_tags(i) for i in concr['words_imperf_verbs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>words_perf_verbs</th>\n",
       "      <th>words_imperf_verbs</th>\n",
       "      <th>things_concr_k10</th>\n",
       "      <th>abstr_concr_k10</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>гребенка</td>\n",
       "      <td>гребенка</td>\n",
       "      <td>0.300831</td>\n",
       "      <td>0.186778</td>\n",
       "      <td>0.243805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>бюджет</td>\n",
       "      <td>бюджет</td>\n",
       "      <td>0.170042</td>\n",
       "      <td>0.259276</td>\n",
       "      <td>0.214659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>письмо</td>\n",
       "      <td>письмо</td>\n",
       "      <td>0.260119</td>\n",
       "      <td>0.216631</td>\n",
       "      <td>0.238375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>правительство</td>\n",
       "      <td>правительство</td>\n",
       "      <td>0.142006</td>\n",
       "      <td>0.263686</td>\n",
       "      <td>0.202846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>зарплата</td>\n",
       "      <td>зарплата</td>\n",
       "      <td>0.166051</td>\n",
       "      <td>0.247007</td>\n",
       "      <td>0.206529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 words_perf_verbs words_imperf_verbs  things_concr_k10  \\\n",
       "0           0         гребенка           гребенка          0.300831   \n",
       "1           1           бюджет             бюджет          0.170042   \n",
       "2           2           письмо             письмо          0.260119   \n",
       "3           3    правительство      правительство          0.142006   \n",
       "4           4         зарплата           зарплата          0.166051   \n",
       "\n",
       "   abstr_concr_k10      mean  \n",
       "0         0.186778  0.243805  \n",
       "1         0.259276  0.214659  \n",
       "2         0.216631  0.238375  \n",
       "3         0.263686  0.202846  \n",
       "4         0.247007  0.206529  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17004171])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concr.loc[concr['words_perf_verbs'] == 'бюджет', 'things_concr_k10'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_concr(corpus, df):\n",
    "    \n",
    "    global_concr = []\n",
    "    global_abstr = []\n",
    "    \n",
    "    for seq in corpus:\n",
    "        local_concr = []\n",
    "        local_abstr = []\n",
    "        for word in seq.split():\n",
    "            if word in df['words_perf_verbs'].values:\n",
    "                local_concr.append(df.loc[df['words_perf_verbs'] == word, 'things_concr_k10'].values[0])\n",
    "                local_abstr.append(df.loc[df['words_perf_verbs'] == word, 'abstr_concr_k10'].values[0])\n",
    "            \n",
    "            elif word in df['words_imperf_verbs'].values:\n",
    "                local_concr.append(df.loc[df['words_imperf_verbs'] == word, 'things_concr_k10'].values[0])\n",
    "                local_abstr.append(df.loc[df['words_imperf_verbs'] == word, 'abstr_concr_k10'].values[0])\n",
    "                \n",
    "        global_concr.append(np.mean(local_concr))  \n",
    "        global_abstr.append(np.mean(local_abstr))\n",
    "    \n",
    "    return global_concr, global_abstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_concr, global_abstr = count_concr(list(pos_lemma['sents']), concr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['concr'] = global_concr\n",
    "df['abstr'] = global_abstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pos-lex-abstr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "      <th>sentid</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>pos</th>\n",
       "      <th>concr</th>\n",
       "      <th>abstr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>бомбардировать#1</td>\n",
       "      <td>['время', 'ребенок', 'музыка']</td>\n",
       "      <td>['ADV', 'PART', ',', 'SPRO', 'PART', 'ADV', 'A...</td>\n",
       "      <td>0.246517</td>\n",
       "      <td>0.213053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>бомбардировать#2</td>\n",
       "      <td>['добрынин', 'говорить', 'шевченко', 'центр', ...</td>\n",
       "      <td>['S anim nom', 'ADV', 'V ipf praet indic', 'S ...</td>\n",
       "      <td>0.181383</td>\n",
       "      <td>0.199301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>бомбардировать#3</td>\n",
       "      <td>['принять', 'внимание', 'настойчиво', 'группа'...</td>\n",
       "      <td>['CONJ', 'V pf - inf', 'ВО', 'S inan acc', ','...</td>\n",
       "      <td>0.152103</td>\n",
       "      <td>0.233698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  class            sentid  \\\n",
       "0      0      1  бомбардировать#1   \n",
       "1      1      1  бомбардировать#2   \n",
       "2      2      1  бомбардировать#3   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0                     ['время', 'ребенок', 'музыка']   \n",
       "1  ['добрынин', 'говорить', 'шевченко', 'центр', ...   \n",
       "2  ['принять', 'внимание', 'настойчиво', 'группа'...   \n",
       "\n",
       "                                                 pos     concr     abstr  \n",
       "0  ['ADV', 'PART', ',', 'SPRO', 'PART', 'ADV', 'A...  0.246517  0.213053  \n",
       "1  ['S anim nom', 'ADV', 'V ipf praet indic', 'S ...  0.181383  0.199301  \n",
       "2  ['CONJ', 'V pf - inf', 'ВО', 'S inan acc', ','...  0.152103  0.233698  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings from BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained('bert-base-multilingual-cased', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119547"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased', config=config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [torch.tensor(tokenizer.encode(i, add_special_tokens=True)) \n",
    "                  for i in list(pos_lemma['sents'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7077/7077 [01:05<00:00, 108.87it/s]\n"
     ]
    }
   ],
   "source": [
    "clear_stdin()\n",
    "sentence_embeddings = []\n",
    "\n",
    "for i in tqdm(input_ids):\n",
    "    _, outputs = model(i.unsqueeze(0).to(device))\n",
    "    sentence_embeddings.append(torch.mean(outputs[0], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([i.tolist() for i in sentence_embeddings]).to_csv('bert_embeds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(outputs[1][0], dim=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on multiple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_df_1 = pd.read_csv('./artm/thetas/metcorp_tm_lda40.csv', index_col=None)\n",
    "theta_df_2 = pd.read_csv('./artm/thetas/metcorp_tm_sparse40.csv', index_col=None)\n",
    "theta_df_3 = pd.read_csv('./artm/thetas/metcorp_tm_dense_280.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "concr = pd.read_csv('pos-lex-abstr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_dict = ['бомбардировать', 'доить', 'греть', 'нападать', \n",
    "             'очертить', 'отрубить', 'пилить', \n",
    "             'подхватывать', 'причесать', 'распылять', \n",
    "             'разбавлять', 'съедать', 'трубить', 'уколоть', \n",
    "             'утюжить', 'выкраивать', 'взорвать', \n",
    "             'взвесить', 'зажигать', 'жонглировать']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(train_list, test_list, clf, train_fold_labels):\n",
    "    train = pd.concat(train_list, axis=1)\n",
    "    test = pd.concat(test_list, axis=1)\n",
    "    pipeline = Pipeline([('scaler', MinMaxScaler()), ('clf', clf)])\n",
    "    pipeline.fit(train, train_fold_labels)\n",
    "    predictions = pipeline.predict(test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embs = np.array([i.cpu().tolist() for i in sentence_embeddings]).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7077, 768)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['class'].values\n",
    "\n",
    "X_lex = df['lemmas']\n",
    "X_pos = df['pos']\n",
    "X_conc = concr[['concr', 'abstr']].values\n",
    "\n",
    "X_tm_1 = theta_df_1.iloc[:, 3:].values\n",
    "X_tm_2 = theta_df_2.iloc[:, 3:].values\n",
    "X_tm_3 = theta_df_3.iloc[:, 3:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7077, 7077, 7077, 7077)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y), len(X_lex), len(X_pos), len(theta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_tm_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Training script is at the end of this notebook for convenience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LEX:  0.8164476473081814\n",
      "Accuracy POS:  0.675710046629928\n",
      "Accuracy CONC:  0.7172530733361594\n",
      "Accuracy EMB:  0.7195139183269748\n",
      "Accuracy LEX+EMB:  0.8074042673449202\n",
      "Accuracy LEX+POS:  0.8204041260421082\n",
      "Accuracy LEX+CONC:  0.8326974706796665\n",
      "Accuracy LEX+POS+CONC:  0.8352409212943338\n",
      "Accuracy LEX+POS+EMB:  0.8124911685742546\n",
      "Accuracy LEX+EMB+CONC:  0.8117846545146249\n",
      "Accuracy LEX+POS+EMB+CONC:  0.817578069803589\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "train_process(X_lex, X_pos, X_conc, y, X_emb=bert_embs, X_tm=None, verb_dict=verb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LEX+TM:  0.8321322594319627\n",
      "Accuracy POS+TM:  0.6149498375017662\n",
      "Accuracy CONC+TM:  0.7508831425745373\n",
      "Accuracy EMB+TM:  0.7255899392397909\n",
      "Accuracy EMB+CONC+TM:  0.5270594884838208\n",
      "Accuracy LEX+EMB+TM:  0.8124911685742546\n",
      "Accuracy LEX+CONC+TM:  0.8372191606612972\n",
      "Accuracy LEX+POS+TM:  0.8346757100466299\n",
      "Accuracy LEX+POS+CONC+TM:  0.8404691253355941\n",
      "Accuracy LEX+POS+CONC+EMB+TM:  0.8133389854458104\n"
     ]
    }
   ],
   "source": [
    "# ARTM sparse\n",
    "train_process(X_lex, X_pos, X_conc, y, X_emb=bert_embs, X_tm=X_tm_2, skip_non_tm=True, verb_dict=verb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LEX+TM:  0.834534407234704\n",
      "Accuracy POS+TM:  0.5971456831990957\n",
      "Accuracy CONC+TM:  0.76162215628091\n",
      "Accuracy EMB+TM:  0.7315246573406811\n",
      "Accuracy EMB+CONC+TM:  0.523103009749894\n",
      "Accuracy LEX+EMB+TM:  0.8075455701568461\n",
      "Accuracy LEX+CONC+TM:  0.8400452168998163\n",
      "Accuracy LEX+POS+TM:  0.8394800056521124\n",
      "Accuracy LEX+POS+CONC+TM:  0.8452734209410767\n",
      "Accuracy LEX+POS+CONC+EMB+TM:  0.8117846545146249\n"
     ]
    }
   ],
   "source": [
    "# ARTM dense\n",
    "train_process(X_lex, X_pos, X_conc, y, X_emb=bert_embs, X_tm=X_tm_3, skip_non_tm=True, verb_dict=verb_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LEX:  0.8172954641797372\n",
      "Accuracy POS:  0.6748622297583722\n",
      "Accuracy CONC:  0.7158400452168998\n",
      "Accuracy EMB:  0.7309594460929772\n",
      "Accuracy LEX+EMB:  0.8483820828034477\n",
      "Accuracy LEX+POS:  0.8201215204182564\n",
      "Accuracy LEX+CONC:  0.8326974706796665\n",
      "Accuracy LEX+POS+CONC:  0.8349583156704818\n",
      "Accuracy LEX+POS+EMB:  0.8530450755970044\n",
      "Accuracy LEX+EMB+CONC:  0.854316800904338\n",
      "Accuracy LEX+POS+EMB+CONC:  0.8584145824501908\n",
      "Accuracy LEX+TM:  0.8332626819273704\n",
      "Accuracy POS+TM:  0.5407658612406386\n",
      "Accuracy CONC+TM:  0.7477744807121661\n",
      "Accuracy EMB+TM:  0.7469266638406105\n",
      "Accuracy EMB+CONC+TM:  0.5256464603645613\n",
      "Accuracy LEX+EMB+TM:  0.8540341952804861\n",
      "Accuracy LEX+CONC+TM:  0.8359474353539635\n",
      "Accuracy LEX+POS+TM:  0.8331213791154444\n",
      "Accuracy LEX+POS+CONC+TM:  0.8369365550374452\n",
      "Accuracy LEX+POS+CONC+EMB+TM:  0.8558711318355235\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "train_process(X_lex, X_pos, X_conc, y, X_emb=bert_embs, X_tm=X_tm_1, skip_non_tm=False, \n",
    "              verb_dict=verb_dict, clf='logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LEX:  0.8172954641797372\n",
      "Accuracy POS:  0.6748622297583722\n",
      "Accuracy CONC:  0.7158400452168998\n",
      "Accuracy EMB:  0.7309594460929772\n",
      "Accuracy LEX+EMB:  0.8483820828034477\n",
      "Accuracy LEX+POS:  0.8201215204182564\n",
      "Accuracy LEX+CONC:  0.8326974706796665\n",
      "Accuracy LEX+POS+CONC:  0.8349583156704818\n",
      "Accuracy LEX+POS+EMB:  0.8530450755970044\n",
      "Accuracy LEX+EMB+CONC:  0.854316800904338\n",
      "Accuracy LEX+POS+EMB+CONC:  0.8584145824501908\n",
      "Accuracy LEX+TM:  0.8319909566200367\n",
      "Accuracy POS+TM:  0.5517874805708634\n",
      "Accuracy CONC+TM:  0.7411332485516462\n",
      "Accuracy EMB+TM:  0.745372332909425\n",
      "Accuracy EMB+CONC+TM:  0.5259290659884132\n",
      "Accuracy LEX+EMB+TM:  0.8536102868447082\n",
      "Accuracy LEX+CONC+TM:  0.8348170128585559\n",
      "Accuracy LEX+POS+TM:  0.8324148650558146\n",
      "Accuracy LEX+POS+CONC+TM:  0.8346757100466299\n",
      "Accuracy LEX+POS+CONC+EMB+TM:  0.854175498092412\n"
     ]
    }
   ],
   "source": [
    "# ARTM sparse\n",
    "train_process(X_lex, X_pos, X_conc, y, X_emb=bert_embs, X_tm=X_tm_2, skip_non_tm=False, \n",
    "              verb_dict=verb_dict, clf='logreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LEX:  0.8172954641797372\n",
      "Accuracy POS:  0.6748622297583722\n",
      "Accuracy CONC:  0.7158400452168998\n",
      "Accuracy EMB:  0.7309594460929772\n",
      "Accuracy LEX+EMB:  0.8483820828034477\n",
      "Accuracy LEX+POS:  0.8201215204182564\n",
      "Accuracy LEX+CONC:  0.8326974706796665\n",
      "Accuracy LEX+POS+CONC:  0.8349583156704818\n",
      "Accuracy LEX+POS+EMB:  0.8530450755970044\n",
      "Accuracy LEX+EMB+CONC:  0.854316800904338\n",
      "Accuracy LEX+POS+EMB+CONC:  0.8584145824501908\n",
      "Accuracy LEX+TM:  0.8185671894870707\n",
      "Accuracy POS+TM:  0.6263953652677688\n",
      "Accuracy CONC+TM:  0.7312420517168292\n",
      "Accuracy EMB+TM:  0.7353398332626819\n",
      "Accuracy EMB+CONC+TM:  0.5221138900664123\n",
      "Accuracy LEX+EMB+TM:  0.8490885968630776\n",
      "Accuracy LEX+CONC+TM:  0.827893175074184\n",
      "Accuracy LEX+POS+TM:  0.8199802176063303\n",
      "Accuracy LEX+POS+CONC+TM:  0.8287409919457397\n",
      "Accuracy LEX+POS+CONC+EMB+TM:  0.8520559559135227\n"
     ]
    }
   ],
   "source": [
    "# ARTM dense\n",
    "train_process(X_lex, X_pos, X_conc, y, X_emb=bert_embs, X_tm=X_tm_3, skip_non_tm=False, \n",
    "              verb_dict=verb_dict, clf='logreg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LEX:  0.8171541613678113\n",
      "Accuracy POS:  0.6762752578776318\n",
      "Accuracy CONC:  0.7173943761480853\n",
      "Accuracy EMB:  0.7407093401158683\n",
      "Accuracy LEX+EMB:  0.8318496538081108\n",
      "Accuracy LEX+POS:  0.8199802176063303\n",
      "Accuracy LEX+CONC:  0.8332626819273704\n",
      "Accuracy LEX+POS+CONC:  0.834393104422778\n",
      "Accuracy LEX+POS+EMB:  0.844566906881447\n",
      "Accuracy LEX+EMB+CONC:  0.8384908859686308\n",
      "Accuracy LEX+POS+EMB+CONC:  0.8485233856153738\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "train_process(X_lex, X_pos, X_conc, y, X_emb=bert_embs, X_tm=None, skip_non_tm=False, \n",
    "              verb_dict=verb_dict, clf='nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LEX+TM:  0.831001836936555\n",
      "Accuracy POS+TM:  0.5954500494559841\n",
      "Accuracy CONC+TM:  0.7534265931892045\n",
      "Accuracy EMB+TM:  0.7346333192030522\n",
      "Accuracy EMB+CONC+TM:  0.5276246997315247\n",
      "Accuracy LEX+EMB+TM:  0.8362300409778155\n",
      "Accuracy LEX+CONC+TM:  0.8331213791154444\n",
      "Accuracy LEX+POS+TM:  0.8322735622438886\n",
      "Accuracy LEX+POS+CONC+TM:  0.8365126466016674\n",
      "Accuracy LEX+POS+CONC+EMB+TM:  0.8492298996750035\n"
     ]
    }
   ],
   "source": [
    "# ARTM sparse\n",
    "train_process(X_lex, X_pos, X_conc, y, X_emb=bert_embs, X_tm=X_tm_2, skip_non_tm=True, \n",
    "              verb_dict=verb_dict, clf='nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LEX+TM:  0.8230888794687015\n",
      "Accuracy POS+TM:  0.6133955065705807\n",
      "Accuracy CONC+TM:  0.7542744100607602\n",
      "Accuracy EMB+TM:  0.7103292355517875\n",
      "Accuracy EMB+CONC+TM:  0.5228204041260421\n",
      "Accuracy LEX+EMB+TM:  0.8399039140878903\n",
      "Accuracy LEX+CONC+TM:  0.8321322594319627\n",
      "Accuracy LEX+POS+TM:  0.8252084216475908\n",
      "Accuracy LEX+POS+CONC+TM:  0.8338278931750742\n",
      "Accuracy LEX+POS+CONC+EMB+TM:  0.8332626819273704\n"
     ]
    }
   ],
   "source": [
    "# ARTM dense\n",
    "train_process(X_lex, X_pos, X_conc, y, X_emb=bert_embs, X_tm=X_tm_3, skip_non_tm=True, \n",
    "              verb_dict=verb_dict, clf='nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(X_lex, X_pos, X_conc, y, X_emb, \n",
    "                  X_tm=False, skip_non_tm=False, verb_dict=None, k_folds=5, clf='svc'):\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=0)\n",
    "    all_test_accuracies = {}\n",
    "    all_results = {}\n",
    "    all_outcomes = {}\n",
    "    \n",
    "    y = y.ravel()\n",
    "    \n",
    "    X_lex = X_lex\n",
    "    X_pos = X_pos\n",
    "    X_conc = X_conc\n",
    "    X_emb = X_emb\n",
    "\n",
    "    alltrue = []\n",
    "    all_test_indices = []\n",
    "    \n",
    "    if not skip_non_tm:\n",
    "        allpredictions_lex = []\n",
    "        allpredictions_pos = []\n",
    "        allpredictions_conc = []\n",
    "        allpredictions_emb = []\n",
    "        allpredictions_lex_pos = []\n",
    "        allpredictions_lex_conc = []\n",
    "        allpredictions_lex_emb = []\n",
    "        allpredictions_lex_pos_conc = []\n",
    "        allpredictions_lex_pos_emb = []\n",
    "        allpredictions_lex_emb_conc = []\n",
    "        allpredictions_lex_pos_emb_conc = []\n",
    "    \n",
    "    if X_tm is not None:\n",
    "        X_tm = X_tm\n",
    "        allpredictions_lex_tm = []\n",
    "        allpredictions_pos_tm = []\n",
    "        allpredictions_emb_tm = []\n",
    "        allpredictions_conc_tm = []\n",
    "        allpredictions_lex_emb_tm = []\n",
    "        allpredictions_lex_pos_tm = []\n",
    "        allpredictions_lex_conc_tm = []\n",
    "        allpredictions_emb_conc_tm = []\n",
    "        allpredictions_lex_pos_conc_tm = []\n",
    "        allpredictions_lex_pos_emb_tm = []\n",
    "        allpredictions_lex_pos_conc_emb_tm = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_lex, y):\n",
    "        lex_train_fold, lex_test_fold = X_lex[train_index], X_lex[test_index]\n",
    "        lex_train_fold, lex_test_fold = [ast.literal_eval(x) for x in lex_train_fold], [ast.literal_eval(x) for x in lex_test_fold]\n",
    "\n",
    "        pos_train_fold, pos_test_fold = X_pos[train_index], X_pos[test_index]\n",
    "        pos_train_fold, pos_test_fold = [ast.literal_eval(x) for x in pos_train_fold], [ast.literal_eval(x) for x in pos_test_fold]\n",
    "        \n",
    "        conc_train, conc_test = X_conc[train_index], X_conc[test_index]\n",
    "        emb_train, emb_test = X_emb[train_index], X_emb[test_index]\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        emb_train, emb_test = scaler.fit_transform(emb_train), scaler.transform(emb_test)\n",
    "        \n",
    "        if X_tm is not None:\n",
    "            tm_train_fold, tm_test_fold = X_tm[train_index], X_tm[test_index]\n",
    "\n",
    "        train_fold_labels, test_fold_labels = y[train_index], y[test_index]\n",
    "        alltrue += test_fold_labels.tolist()\n",
    "        \n",
    "        all_test_indices += list(test_index)\n",
    "        \n",
    "        lex_train_pairs = list(zip(train_fold_labels, lex_train_fold))\n",
    "        lex_test_pairs = list(zip(test_fold_labels, lex_test_fold))\n",
    "\n",
    "        lex_train_freq_table = freq_table(lex_train_pairs, verb_dict)  \n",
    "        lex_frequencies = lex_train_freq_table[0]\n",
    "        lex_met_corpus_size = lex_train_freq_table[1]\n",
    "        lex_nonmet_corpus_size = lex_train_freq_table[2]\n",
    "\n",
    "        lex_train_statistics = compute_statistics(lex_frequencies, lex_met_corpus_size, \n",
    "                                                   lex_nonmet_corpus_size)\n",
    "\n",
    "        lex_train = assign_scores(lex_train_fold, lex_train_statistics)\n",
    "        lex_test = assign_scores(lex_test_fold, lex_train_statistics)\n",
    "\n",
    "        pos_train_pairs = list(zip(train_fold_labels, pos_train_fold))\n",
    "        pos_test_pairs = list(zip(test_fold_labels, pos_test_fold))\n",
    "\n",
    "        pos_train_freq_table = freq_table(pos_train_pairs, verb_dict)        \n",
    "        pos_frequencies = pos_train_freq_table[0]\n",
    "        pos_met_corpus_size = pos_train_freq_table[1]\n",
    "        pos_nonmet_corpus_size = pos_train_freq_table[2]\n",
    "\n",
    "        pos_train_statistics = compute_statistics(pos_frequencies, pos_met_corpus_size, \n",
    "                                                   pos_nonmet_corpus_size)\n",
    "\n",
    "        pos_train = assign_scores(pos_train_fold, pos_train_statistics)\n",
    "        pos_test = assign_scores(pos_test_fold, pos_train_statistics)\n",
    "        \n",
    "        if clf == 'svc':\n",
    "            clf = LinearSVC(penalty = 'l2', loss = 'squared_hinge', dual = False, \n",
    "                        C = 1000, multi_class = 'ovr', random_state=0)\n",
    "        elif clf == 'nn':\n",
    "            clf = MLPClassifier(alpha=0.1, max_iter=5000, learning_rate='adaptive')\n",
    "        \n",
    "        elif clf == 'logreg':\n",
    "            clf = LogisticRegression(class_weight='balanced', solver='liblinear', \n",
    "                                     fit_intercept=True, max_iter=10000)\n",
    "        if not skip_non_tm:\n",
    "            clf_lex = clf       \n",
    "            clf_pos = clf\n",
    "            clf_conc = clf\n",
    "            clf_emb = clf\n",
    "            clf_lex_pos = clf\n",
    "            clf_lex_conc = clf\n",
    "            clf_lex_emb = clf\n",
    "            clf_lex_pos_conc = clf\n",
    "            clf_lex_pos_emb = clf\n",
    "            clf_lex_emb_conc = clf\n",
    "            clf_lex_pos_emb_conc = clf\n",
    "        \n",
    "            # LEX\n",
    "            clf_lex.fit(lex_train, train_fold_labels)\n",
    "            predictions_lex = clf_lex.predict(lex_test)\n",
    "\n",
    "            # POS\n",
    "            clf_pos.fit(pos_train, train_fold_labels)\n",
    "            predictions_pos = clf_pos.predict(pos_test)\n",
    "\n",
    "            # CONC\n",
    "            clf_conc.fit(conc_train, train_fold_labels)\n",
    "            predictions_conc = clf_conc.predict(conc_test)\n",
    "\n",
    "            # EMB\n",
    "            clf_emb.fit(emb_train, train_fold_labels)\n",
    "            predictions_emb = clf_emb.predict(emb_test)\n",
    "\n",
    "            # LEX + POS\n",
    "            predictions_lex_pos = train_and_predict([pd.DataFrame(lex_train), pd.DataFrame(pos_train)],\n",
    "                                                           (pd.DataFrame(lex_test), pd.DataFrame(pos_test)),\n",
    "                                                           clf_lex_pos, train_fold_labels=train_fold_labels)\n",
    "            # LEX + CONC\n",
    "            predictions_lex_conc = train_and_predict([pd.DataFrame(lex_train), pd.DataFrame(conc_train)],\n",
    "                                                           (pd.DataFrame(lex_test), pd.DataFrame(conc_test)),\n",
    "                                                           clf_lex_conc, train_fold_labels=train_fold_labels)\n",
    "\n",
    "            # LEX + EMB\n",
    "            predictions_lex_emb = train_and_predict([pd.DataFrame(lex_train), pd.DataFrame(emb_train)],\n",
    "                                                           (pd.DataFrame(lex_test), pd.DataFrame(emb_test)),\n",
    "                                                           clf_lex_emb, train_fold_labels=train_fold_labels)\n",
    "\n",
    "            # LEX + POS + CONC\n",
    "            predictions_lex_pos_conc = train_and_predict([pd.DataFrame(lex_train), pd.DataFrame(pos_train), \n",
    "                                                     pd.DataFrame(conc_train)], (pd.DataFrame(lex_test), \n",
    "                                                     pd.DataFrame(pos_test), pd.DataFrame(conc_test)),\n",
    "                                                     clf_lex_pos_conc, train_fold_labels=train_fold_labels)\n",
    "            # LEX + POS + EMB\n",
    "            predictions_lex_pos_emb = train_and_predict([pd.DataFrame(lex_train), pd.DataFrame(pos_train), \n",
    "                                                     pd.DataFrame(emb_train)], (pd.DataFrame(lex_test), \n",
    "                                                     pd.DataFrame(pos_test), pd.DataFrame(emb_test)),\n",
    "                                                     clf_lex_pos_emb, train_fold_labels=train_fold_labels)\n",
    "\n",
    "            # LEX + EMB + CONC\n",
    "            predictions_lex_emb_conc = train_and_predict([pd.DataFrame(lex_train), pd.DataFrame(emb_train), \n",
    "                                                     pd.DataFrame(conc_train)], (pd.DataFrame(lex_test), \n",
    "                                                     pd.DataFrame(emb_test), pd.DataFrame(conc_test)),\n",
    "                                                     clf_lex_emb_conc, train_fold_labels=train_fold_labels)\n",
    "            \n",
    "            # LEX + EMB + CONC\n",
    "            predictions_lex_pos_emb_conc = train_and_predict([pd.DataFrame(lex_train), pd.DataFrame(pos_train), \n",
    "                                                     pd.DataFrame(emb_train), pd.DataFrame(conc_train)], \n",
    "                                                     (pd.DataFrame(lex_test), pd.DataFrame(pos_test),\n",
    "                                                     pd.DataFrame(emb_test), pd.DataFrame(conc_test)),\n",
    "                                                     clf_lex_pos_emb_conc, train_fold_labels=train_fold_labels)\n",
    "\n",
    "            allpredictions_lex += list(predictions_lex)\n",
    "            allpredictions_pos += list(predictions_pos)\n",
    "            allpredictions_emb += list(predictions_emb)\n",
    "            allpredictions_conc += list(predictions_conc)\n",
    "            allpredictions_lex_pos += list(predictions_lex_pos)\n",
    "            allpredictions_lex_conc += list(predictions_lex_conc)\n",
    "            allpredictions_lex_emb += list(predictions_lex_emb)\n",
    "            allpredictions_lex_pos_conc += list(predictions_lex_pos_conc)\n",
    "            allpredictions_lex_pos_emb += list(predictions_lex_pos_emb)\n",
    "            allpredictions_lex_emb_conc += list(predictions_lex_emb_conc)\n",
    "            allpredictions_lex_pos_emb_conc += list(predictions_lex_pos_emb_conc)\n",
    "        \n",
    "        if X_tm is not None:\n",
    "            clf_lex_tm = clf\n",
    "            clf_pos_tm = clf\n",
    "            clf_emb_tm = clf\n",
    "            clf_conc_tm = clf\n",
    "            clf_lex_pos_tm = clf\n",
    "            clf_lex_emb_tm = clf\n",
    "            clf_lex_conc_tm = clf\n",
    "            clf_conc_emb_tm = clf\n",
    "            clf_lex_pos_conc_tm = clf\n",
    "            clf_lex_pos_conc_emb_tm = clf\n",
    "            \n",
    "            # LEX + TM\n",
    "            clf_lex_tm.fit(lex_train.join(pd.DataFrame(tm_train_fold), rsuffix='tm'), train_fold_labels)\n",
    "            predictions_lex_tm = clf_lex_tm.predict(lex_test.join(pd.DataFrame(tm_test_fold), rsuffix='tm'))\n",
    "            \n",
    "            # POS + TM\n",
    "            clf_pos_tm.fit(pos_train.join(pd.DataFrame(tm_train_fold), rsuffix='tm'), train_fold_labels)\n",
    "            predictions_pos_tm = clf_pos_tm.predict(pos_test.join(pd.DataFrame(tm_train_fold), rsuffix='tm'))\n",
    "            \n",
    "            # CONC + TM\n",
    "            df_conc_tm_train = pd.DataFrame(conc_train).join(pd.DataFrame(tm_train_fold), rsuffix='tm')\n",
    "            df_conc_tm_test = pd.DataFrame(conc_test).join(pd.DataFrame(tm_test_fold), rsuffix='tm')\n",
    "                                                           \n",
    "            clf_conc_tm.fit(df_conc_tm_train, train_fold_labels)\n",
    "            predictions_conc_tm = clf_conc_tm.predict(df_conc_tm_test)\n",
    "            \n",
    "            # EMB + TM\n",
    "            df_emb_tm_train = pd.DataFrame(emb_train).join(pd.DataFrame(tm_train_fold), rsuffix='tm')\n",
    "            df_emb_tm_test = pd.DataFrame(emb_test).join(pd.DataFrame(tm_test_fold), rsuffix='tm')\n",
    "            \n",
    "            clf_emb_tm.fit(df_emb_tm_train, train_fold_labels) \n",
    "            predictions_emb_tm = clf_emb_tm.predict(df_emb_tm_test)\n",
    "            \n",
    "            # LEX + POS + TM \n",
    "            df_lex_pos_train = lex_train.join(pd.DataFrame(pos_train), rsuffix='pos')\n",
    "            df_lex_pos_test = lex_test.join(pd.DataFrame(pos_test), rsuffix='pos')\n",
    "            \n",
    "            df_lex_pos_tm_train = df_lex_pos_train.join(pd.DataFrame(tm_train_fold), rsuffix='tm')\n",
    "            df_lex_pos_tm_test = df_lex_pos_test.join(pd.DataFrame(tm_test_fold), rsuffix='tm')\n",
    "            \n",
    "            clf_lex_pos_tm.fit(df_lex_pos_tm_train, train_fold_labels)\n",
    "            predictions_lex_pos_tm = clf_lex_pos_tm.predict(df_lex_pos_tm_test)\n",
    "            \n",
    "            # LEX + EMB + TM\n",
    "            df_lex_emb_train = lex_train.join(pd.DataFrame(emb_train), rsuffix='emb')\n",
    "            df_lex_emb_test = lex_test.join(pd.DataFrame(emb_test), rsuffix='emb')\n",
    "            \n",
    "            df_lex_emb_tm_train = df_lex_emb_train.join(pd.DataFrame(tm_train_fold), rsuffix='tm')\n",
    "            df_lex_emb_tm_test = df_lex_emb_test.join(pd.DataFrame(tm_test_fold), rsuffix='tm')\n",
    "            \n",
    "            clf_lex_emb_tm.fit(df_lex_emb_tm_train, train_fold_labels)\n",
    "            predictions_lex_emb_tm = clf_lex_emb_tm.predict(df_lex_emb_tm_test)\n",
    "            \n",
    "            # LEX + CONC + TM\n",
    "            \n",
    "            df_lex_conc_tm_train = df_conc_tm_train.join(lex_train, rsuffix='lex')\n",
    "            df_lex_conc_tm_test = df_conc_tm_test.join(lex_test, rsuffix='lex')\n",
    "            \n",
    "            clf_lex_conc_tm.fit(df_lex_conc_tm_train, train_fold_labels)\n",
    "            predictions_lex_conc_tm = clf_lex_conc_tm.predict(df_lex_conc_tm_test)\n",
    "            \n",
    "            # CONC + EMB + TM\n",
    "            \n",
    "            df_conc_emb_tm_train = df_emb_tm_train.join(lex_train, rsuffix='lex')\n",
    "            df_conc_emb_tm_test = df_emb_tm_test.join(lex_train, rsuffix='lex')\n",
    "            \n",
    "            clf_conc_emb_tm.fit(df_conc_emb_tm_train, train_fold_labels)\n",
    "            predictions_conc_emb_tm = clf_conc_emb_tm.predict(df_conc_emb_tm_test)\n",
    "            \n",
    "            # LEX + POS + CONC + TM\n",
    "            \n",
    "            df_lex_pos_conc_tm_train = df_lex_pos_tm_train.join(pd.DataFrame(conc_train), rsuffix='conc')\n",
    "            df_lex_pos_conc_tm_test = df_lex_pos_tm_test.join(pd.DataFrame(conc_test), rsuffix='conc')\n",
    "            \n",
    "            clf_lex_pos_conc_tm.fit(df_lex_pos_conc_tm_train, train_fold_labels)\n",
    "            predictions_lex_pos_conc_tm = clf_lex_pos_conc_tm.predict(df_lex_pos_conc_tm_test)\n",
    "            \n",
    "            # LEX + POS + CONC + EBM + TM\n",
    "            df_full_train = df_lex_pos_conc_tm_train.join(pd.DataFrame(emb_train), rsuffix='emb')\n",
    "            df_full_test = df_lex_pos_conc_tm_test.join(pd.DataFrame(emb_test), rsuffix='emb')\n",
    "            \n",
    "            clf_lex_pos_conc_emb_tm.fit(df_full_train, train_fold_labels)\n",
    "            predictions_lex_pos_conc_emb_tm = clf_lex_pos_conc_emb_tm.predict(df_full_test)\n",
    "            \n",
    "            allpredictions_lex_tm += list(predictions_lex_tm)\n",
    "            allpredictions_pos_tm += list(predictions_pos_tm)\n",
    "            allpredictions_conc_tm += list(predictions_conc_tm)\n",
    "            allpredictions_emb_tm += list(predictions_emb_tm)\n",
    "            allpredictions_emb_conc_tm += list(predictions_conc_emb_tm)   #*\n",
    "            allpredictions_lex_emb_tm += list(predictions_lex_emb_tm)\n",
    "            allpredictions_lex_conc_tm += list(predictions_lex_conc_tm)\n",
    "            allpredictions_lex_pos_tm += list(predictions_lex_pos_tm)\n",
    "            allpredictions_lex_pos_conc_tm += list(predictions_lex_pos_conc_tm)\n",
    "            allpredictions_lex_pos_conc_emb_tm += list(predictions_lex_pos_conc_emb_tm)\n",
    "    \n",
    "    if not skip_non_tm:\n",
    "        accuracy_lex = accuracy_score(alltrue, allpredictions_lex)\n",
    "        accuracy_pos = accuracy_score(alltrue, allpredictions_pos)\n",
    "        accuracy_conc = accuracy_score(alltrue, allpredictions_conc)\n",
    "        accuracy_emb = accuracy_score(alltrue, allpredictions_emb)\n",
    "        accuracy_lex_conc = accuracy_score(alltrue, allpredictions_lex_conc)\n",
    "        accuracy_lex_emb = accuracy_score(alltrue, allpredictions_lex_emb)\n",
    "        accuracy_lex_pos = accuracy_score(alltrue, allpredictions_lex_pos)\n",
    "        accuracy_lex_pos_conc = accuracy_score(alltrue, allpredictions_lex_pos_conc)\n",
    "        accuracy_lex_pos_emb = accuracy_score(alltrue, allpredictions_lex_pos_emb)\n",
    "        accuracy_lex_emb_conc = accuracy_score(alltrue, allpredictions_lex_emb_conc)\n",
    "        accuracy_lex_pos_emb_conc = accuracy_score(alltrue, allpredictions_lex_pos_emb_conc)\n",
    "\n",
    "\n",
    "        print('Accuracy LEX: ', accuracy_lex)\n",
    "        print('Accuracy POS: ', accuracy_pos)\n",
    "        print('Accuracy CONC: ', accuracy_conc)\n",
    "        print('Accuracy EMB: ', accuracy_emb)\n",
    "        print('Accuracy LEX+EMB: ', accuracy_lex_emb)\n",
    "        print('Accuracy LEX+POS: ', accuracy_lex_pos)\n",
    "        print('Accuracy LEX+CONC: ', accuracy_lex_conc)\n",
    "        print('Accuracy LEX+POS+CONC: ', accuracy_lex_pos_conc)\n",
    "        print('Accuracy LEX+POS+EMB: ', accuracy_lex_pos_emb)\n",
    "        print('Accuracy LEX+EMB+CONC: ', accuracy_lex_emb_conc)\n",
    "        print('Accuracy LEX+POS+EMB+CONC: ', accuracy_lex_pos_emb_conc)\n",
    "    \n",
    "    \n",
    "    if X_tm is not None:\n",
    "        \n",
    "        accuracy_lex_tm = accuracy_score(alltrue, allpredictions_lex_tm)\n",
    "        accuracy_pos_tm = accuracy_score(alltrue, allpredictions_pos_tm)\n",
    "        accuracy_conc_tm = accuracy_score(alltrue, allpredictions_conc_tm)\n",
    "        accuracy_emb_tm = accuracy_score(alltrue, allpredictions_emb_tm)\n",
    "        accuracy_lex_emb_tm = accuracy_score(alltrue, allpredictions_lex_emb_tm)\n",
    "        accuracy_emb_conc_tm = accuracy_score(alltrue, allpredictions_emb_conc_tm)\n",
    "        accuracy_lex_pos_tm = accuracy_score(alltrue, allpredictions_lex_pos_tm)\n",
    "        accuracy_lex_conc_tm = accuracy_score(alltrue, allpredictions_lex_conc_tm)\n",
    "        accuracy_lex_pos_conc_tm = accuracy_score(alltrue, allpredictions_lex_pos_conc_tm)\n",
    "        accuracy_lex_pos_conc_emb_tm = accuracy_score(alltrue, allpredictions_lex_pos_conc_emb_tm)\n",
    "        \n",
    "        \n",
    "        print('Accuracy LEX+TM: ', accuracy_lex_tm)\n",
    "        print('Accuracy POS+TM: ', accuracy_pos_tm)\n",
    "        print('Accuracy CONC+TM: ', accuracy_conc_tm)\n",
    "        print('Accuracy EMB+TM: ', accuracy_emb_tm)\n",
    "        print('Accuracy EMB+CONC+TM: ', accuracy_emb_conc_tm)\n",
    "        print('Accuracy LEX+EMB+TM: ', accuracy_lex_emb_tm)\n",
    "        print('Accuracy LEX+CONC+TM: ', accuracy_lex_conc_tm)      \n",
    "        print('Accuracy LEX+POS+TM: ', accuracy_lex_pos_tm)\n",
    "        print('Accuracy LEX+POS+CONC+TM: ', accuracy_lex_pos_conc_tm)\n",
    "        print('Accuracy LEX+POS+CONC+EMB+TM: ', accuracy_lex_pos_conc_emb_tm)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
