{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metaphor Identification using Pre-Trained Topic Models\n",
    "#### *Adridged Pipepine*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import artm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_N = 40   # specify number of topics\n",
    "\n",
    "dictionary = artm.Dictionary()   # initialize Dictionary object\n",
    "dictionary = dictionary.load('./artm/wiki_with_bi_artm_dictionary.dict')   # load the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Loading ARTM sparse/dense models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load pre-trained weights, we need to first create the empty model with the same params as the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "model = artm.ARTM(num_topics=TOPIC_N, dictionary=dictionary, \n",
    "                          cache_theta=False)\n",
    "# Adding scores\n",
    "model.scores.add(artm.PerplexityScore(name='PerplexityScore', dictionary=dictionary))\n",
    "model.scores.add(artm.SparsityPhiScore(name='SparsityPhiScore'))\n",
    "model.scores.add(artm.SparsityThetaScore(name='SparsityThetaScore'))\n",
    "model.scores.add(artm.TopTokensScore(name='top_words', num_tokens=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse ARTM regularizers\n",
    "artm_regs_sparse = [artm.SmoothSparsePhiRegularizer(name='sparse_phi_regularizer', tau=-1.5),\n",
    "                    artm.SmoothSparseThetaRegularizer(name='sparse_theta_regularizer', tau=-0.5),\n",
    "                    artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', tau=1e+3)\n",
    "                   ]\n",
    "\n",
    "# Dense ARTM regularizers\n",
    "artm_regs_dense = [artm.SmoothSparsePhiRegularizer(name='sparse_phi_regularizer', tau=-1.5),\n",
    "                    artm.SmoothSparseThetaRegularizer(name='sparse_theta_regularizer', tau=0.5),\n",
    "                    artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', tau=1e+3)\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add regularizers. Options: artm_regs_sparse|artm_regs_dense\n",
    "for reg in artm_regs_sparse:\n",
    "    model.regularizers.add(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to load the pre-trained weights. Specify the model location (both `p_wt` and `n_wt` files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load(filename='./artm/models/artm_p_wt_sparse40', model_name='p_wt')\n",
    "model.load(filename='./artm/models/artm_n_wt_sparse40', model_name='n_wt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Loading LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, initialize LDA object with the same parameters as the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = artm.LDA(num_topics=topic_n, alpha=0.01, beta=0.001, cache_theta=False,\n",
    "               num_document_passes=10, dictionary=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.load(filename='saved_p_wt', model_name='p_wt')\n",
    "lda.load(filename='saved_n_wt', model_name='n_wt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Metaphor Corpus and Extracting Topic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan:\n",
    "    \n",
    "    * Load Preprocessed metaphor corpus (in Vowpal Wabbit format)\n",
    "    * Create batches for BigARTM\n",
    "    * Extract topic features (Theta matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we batch dataset for the first time, BigARTM creates a folder with batched documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When creating batch_vectorizer for the corpus for the first time\n",
    "met_batch_vectorizer = artm.BatchVectorizer(data_path='./artm/metcorp_vw.txt', data_format='vowpal_wabbit',\n",
    "                                            target_folder='metcorp_batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we already have files with batches, we can load directly from them (faster, recommended). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # When you already have batches, it's recommended to load from batches:\n",
    "# met_batch_vectorizer = artm.BatchVectorizer(data_path='metcorp_batches', data_format='batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features from the metaphor corpus. Use the `model` (or `lda`) loaded before. \n",
    "\n",
    "`model.transform()` outputs topic distribution as pandas.DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metcorp_theta = model.transform(met_batch_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NB!` Topic numbering starts from $0$, not $1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6000</th>\n",
       "      <th>6001</th>\n",
       "      <th>6002</th>\n",
       "      <th>6003</th>\n",
       "      <th>6004</th>\n",
       "      <th>6005</th>\n",
       "      <th>6006</th>\n",
       "      <th>6007</th>\n",
       "      <th>6008</th>\n",
       "      <th>6009</th>\n",
       "      <th>...</th>\n",
       "      <th>7067</th>\n",
       "      <th>7068</th>\n",
       "      <th>7069</th>\n",
       "      <th>7070</th>\n",
       "      <th>7071</th>\n",
       "      <th>7072</th>\n",
       "      <th>7073</th>\n",
       "      <th>7074</th>\n",
       "      <th>7075</th>\n",
       "      <th>7076</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7077 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         6000  6001  6002  6003  6004      6005  6006  6007  6008  6009  ...  \\\n",
       "topic_0   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0  ...   \n",
       "topic_1   0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0  ...   \n",
       "topic_2   0.0   0.0   0.0   0.0   0.0  0.392546   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "         7067  7068  7069  7070      7071  7072  7073  7074  7075  7076  \n",
       "topic_0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  \n",
       "topic_1   0.0   0.0   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0  \n",
       "topic_2   0.0   0.0   0.0   0.0  0.084376   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[3 rows x 7077 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metcorp_theta.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DataFrame with preprocessed metaphor corpus (not in vowpal wabbit format, for convenience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('metcorp.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert topic distribution for each context in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sents</th>\n",
       "      <th>targets</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_30</th>\n",
       "      <th>topic_31</th>\n",
       "      <th>topic_32</th>\n",
       "      <th>topic_33</th>\n",
       "      <th>topic_34</th>\n",
       "      <th>topic_35</th>\n",
       "      <th>topic_36</th>\n",
       "      <th>topic_37</th>\n",
       "      <th>topic_38</th>\n",
       "      <th>topic_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>нужно_PRED весь_ADJF время_NOUN бомбардировать...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>добрынин_NOUN говорить_VERB шевченко_NOUN цент...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019670</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>принять_INFN внимание_NOUN настойчиво_ADVB гру...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148076</td>\n",
       "      <td>0.205082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429145</td>\n",
       "      <td>0.142618</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sents  targets  topic_0  \\\n",
       "0  нужно_PRED весь_ADJF время_NOUN бомбардировать...        1      0.0   \n",
       "1  добрынин_NOUN говорить_VERB шевченко_NOUN цент...        1      0.0   \n",
       "2  принять_INFN внимание_NOUN настойчиво_ADVB гру...        1      0.0   \n",
       "\n",
       "   topic_1  topic_2  topic_3  topic_4   topic_5   topic_6  topic_7  ...  \\\n",
       "0      0.0      0.0      0.0      0.0  0.000000  0.000000      0.0  ...   \n",
       "1      0.0      0.0      0.0      0.0  0.000000  0.164717      0.0  ...   \n",
       "2      0.0      0.0      0.0      0.0  0.148076  0.205082      0.0  ...   \n",
       "\n",
       "   topic_30  topic_31  topic_32  topic_33  topic_34  topic_35  topic_36  \\\n",
       "0       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   topic_37  topic_38  topic_39  \n",
       "0  0.000000  0.000000       0.0  \n",
       "1  0.000000  0.019670       0.0  \n",
       "2  0.429145  0.142618       0.0  \n",
       "\n",
       "[3 rows x 42 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.join(metcorp_theta.T)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save the Dataframe and reuse it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('metcorp_with_topic_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# from sklearn.gaussian_process.kernels import RBF\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally, there were 11 different classifiers in the experiment, but eventually it was down to the top 3: Logistic Regression, Linear SVM and Neural Network. Uncomment lines with classifiers and their names if you wou want to try other classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Logistic Regression\", \n",
    "         #\"Logisitic Regression SGD\", \n",
    "         \"Linear SVM\", \n",
    "         #\"RBF SVM\", \n",
    "         #\"Naive Bayes\", \n",
    "         #\"Gaussian Process\", \n",
    "         #\"Decision Tree\", \n",
    "         #\"Random Forest\", \n",
    "         \"Neural Net\", \n",
    "         #\"AdaBoost\", \n",
    "         #\"Nearest Heighbors\"\n",
    "         ]\n",
    "\n",
    "classifiers = [LogisticRegression(class_weight='balanced', solver='liblinear', fit_intercept=True, max_iter=10000),\n",
    "               #linear_model.SGDClassifier(max_iter=50000, tol=1e-3, loss='log', class_weight='balanced'),\n",
    "               SVC(kernel=\"linear\", C=0.025, max_iter=10000),\n",
    "               #SVC(gamma=2), \n",
    "               #GaussianNB(),\n",
    "               #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "               #DecisionTreeClassifier(max_depth=10),\n",
    "               #RandomForestClassifier(max_depth=10, n_estimators=10),\n",
    "               MLPClassifier(alpha=0.1, max_iter=5000, learning_rate='adaptive'),\n",
    "               #AdaBoostClassifier(),\n",
    "               #KNeighborsClassifier(n_neighbors=2)\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, k_fold=5):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    train_results = {}    # {'clf': {'accuracy':[], 'precision':[], 'recall':[], 'f1':[])}\n",
    "\n",
    "    #kf = KFold(k_fold, shuffle=True, random_state=42)\n",
    "    kf = StratifiedKFold(k_fold, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_num = 1\n",
    "\n",
    "    for train_ind, val_ind in kf.split(X, y):\n",
    "        # Assign CV IDX\n",
    "        X_train, y_train = X[train_ind], y[train_ind]\n",
    "        X_val, y_val = X[val_ind], y[val_ind]\n",
    "        \n",
    "        # Scale Data\n",
    "        # scaler = StandardScaler()\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scale = scaler.fit_transform(X_train)\n",
    "        X_val_scale = scaler.transform(X_val)\n",
    "        \n",
    "        # print(\"Fold num: \", fold_num)\n",
    "\n",
    "        for name, clf in zip(names, classifiers):\n",
    "\n",
    "            if name not in train_results:\n",
    "                train_results[name] = {'accuracy':[], 'precision':[], 'recall':[], 'f1':[]} # 'train_time':[]}\n",
    "\n",
    "            # print(\"Training: \", name)\n",
    "            #start_time = time.time()\n",
    "\n",
    "            model = clf.fit(X_train_scale, y_train)\n",
    "            y_pred = model.predict(X_val_scale)\n",
    "\n",
    "            train_results[name]['accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "            train_results[name]['precision'].append(precision_score(y_val, y_pred))\n",
    "            train_results[name]['recall'].append(recall_score(y_val, y_pred))\n",
    "            train_results[name]['f1'].append(f1_score(y_val, y_pred))\n",
    "            #train_results[name]['train_time'].append(time.time() - start_time)\n",
    "\n",
    "            #print(\"Run Time: \", time.time() - start_time)\n",
    "        \n",
    "        fold_num += 1\n",
    "        # print()\n",
    "    return train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(results):   \n",
    "    '''Print metrics for all tested classifiers\n",
    "    '''     \n",
    "    for clf, scores in results.items():\n",
    "        print(\"Scores for \", clf)\n",
    "        print(f\"\\t Train accuracy: {np.mean(scores['accuracy']):.3f} +- {np.std(scores['accuracy']):.3f}\")\n",
    "        print(f\"\\t Train precision: {np.mean(scores['precision']):.3f} +- {np.std(scores['precision']):.3f}\")\n",
    "        print(f\"\\t Train recall: {np.mean(scores['recall']):.3f} +- {np.std(scores['recall']):.3f}\")\n",
    "        print(f\"\\t Train f1-score: {np.mean(scores['f1']):.3f} +- {np.std(scores['f1']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training & Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load if not loaded yet\n",
    "# df = pd.read_csv('./artm/metcorp_with_topic_features.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 3:].values.tolist()   # X is columns with topic distributions\n",
    "y = df['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for  Logistic Regression\n",
      "\t Train accuracy: 0.668 +- 0.008\n",
      "\t Train precision: 0.653 +- 0.007\n",
      "\t Train recall: 0.718 +- 0.017\n",
      "\t Train f1-score: 0.684 +- 0.010\n",
      "Scores for  Linear SVM\n",
      "\t Train accuracy: 0.648 +- 0.009\n",
      "\t Train precision: 0.616 +- 0.007\n",
      "\t Train recall: 0.788 +- 0.016\n",
      "\t Train f1-score: 0.691 +- 0.009\n",
      "Scores for  Neural Net\n",
      "\t Train accuracy: 0.674 +- 0.012\n",
      "\t Train precision: 0.659 +- 0.016\n",
      "\t Train recall: 0.727 +- 0.015\n",
      "\t Train f1-score: 0.691 +- 0.009\n"
     ]
    }
   ],
   "source": [
    "train_results = train(X, y)\n",
    "scores(train_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
